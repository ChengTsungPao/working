{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers : Fundamental blocks of Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import Linear, ReLU\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.autograd import Variable\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear(in_features,out_features,bias)\n",
    "\n",
    "定義 輸入和輸出層的維度(weight的維度)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.6138, -0.6005,  0.1217,  1.1433,  1.2532]],\n",
       "       grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myLayer = Linear(in_features=10,out_features=5,bias=True)\n",
    "inp = Variable(torch.randn(1,10))\n",
    "myLayer = Linear(in_features=10,out_features=5,bias=True) \n",
    "myLayer(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.2563, -0.2979,  0.2679, -0.0872, -0.2517,  0.2666, -0.2537,  0.2673,\n",
       "         -0.1313,  0.0095],\n",
       "        [ 0.2295,  0.1175,  0.0512, -0.1537, -0.2360, -0.2800, -0.0673, -0.0395,\n",
       "         -0.0121,  0.2237],\n",
       "        [ 0.0227,  0.1262, -0.1672, -0.2167, -0.0580,  0.2146,  0.2710, -0.1066,\n",
       "         -0.2871, -0.0474],\n",
       "        [-0.3156,  0.0862, -0.1411,  0.0072, -0.1518, -0.1100, -0.1887,  0.0707,\n",
       "         -0.0701, -0.1305],\n",
       "        [-0.2692,  0.1937, -0.0219, -0.0184, -0.1888,  0.3106,  0.1528, -0.2884,\n",
       "         -0.2803,  0.2189]], requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myLayer.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 0.0489, -0.1796,  0.0931,  0.2196,  0.0039], requires_grad=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myLayer.bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stacking Linear layers\n",
    "\n",
    "建立多層神經層透過迭代"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2094, 0.1383]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myLayer1 = Linear(10,5)\n",
    "myLayer2 = Linear(5,2)\n",
    "myLayer2(myLayer1(inp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTorch Non-linear Activations\n",
    "\n",
    "使用兩種呼叫激勵函數的不同方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 0., 0.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_data = Variable(torch.Tensor([[1,2,-1,-1]])) \n",
    "myRelu = ReLU()\n",
    "myRelu(sample_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 0., 0.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "sample_data = Variable(torch.Tensor([[1,2,-1,-1]])) \n",
    "f = F.relu(sample_data) # Much simpler.\n",
    "f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network \n",
    "\n",
    "利用類別建立多層神經網路"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyFirstNetwork(\n",
      "  (layer1): Linear(in_features=50176, out_features=3136, bias=True)\n",
      "  (layer2): Linear(in_features=3136, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class MyFirstNetwork(nn.Module):\n",
    "    def __init__(self,input_size,hidden_size,output_size):\n",
    "        super(MyFirstNetwork,self).__init__() \n",
    "        self.layer1 = nn.Linear(input_size,hidden_size) \n",
    "        self.layer2 = nn.Linear(hidden_size,output_size)\n",
    "    def layer(self):\n",
    "        first  = [self.layer1.weight.data,self.layer1.bias.data]\n",
    "        second = [self.layer2.weight.data,self.layer2.bias.data]\n",
    "        return first,second\n",
    "    def forward(self,input): \n",
    "        out = self.layer1(input) \n",
    "        out = F.relu(out)\n",
    "        out = self.layer2(out) \n",
    "        out = F.softmax(out,dim=1)\n",
    "        return out\n",
    "\n",
    "model = MyFirstNetwork(224*224,56*56,2)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss\n",
    "\n",
    "介紹兩種不同的loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.MSELoss()\n",
    "input = Variable(torch.randn(3, 5), requires_grad=True) \n",
    "target = Variable(torch.randn(3, 5))\n",
    "output = loss(input, target)\n",
    "output.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分類問題常用的loss function: 交叉熵(cross-entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(true_label, prediction):\n",
    "    if true_label == 1:\n",
    "        return -log(prediction)\n",
    "    else:\n",
    "        return -log(1 - prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss(x,class)=−x[class]+log(∑exp(x[j]))\n",
    "\n",
    "利用上述公式自訂函數與內建函數比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7645517587661743\n",
      "1.764551785993138\n"
     ]
    }
   ],
   "source": [
    "loss = nn.CrossEntropyLoss()\n",
    "input = Variable(torch.randn(3, 5), requires_grad=True) \n",
    "target = Variable(torch.LongTensor(3).random_(5)) \n",
    "output = loss(input, target)\n",
    "output.backward()\n",
    "print(output.data.item())\n",
    "\n",
    "def CrossEntropyLoss(input,target):\n",
    "    sum = 0\n",
    "    for i in range(len(input)):\n",
    "        tmp = 0\n",
    "        for j in range(len(input[0])):\n",
    "            tmp+=np.e**(input[i][j])\n",
    "        sum+=-input[i][target[i]]+np.log(tmp)\n",
    "    return float(sum)/len(input)\n",
    "\n",
    "print(CrossEntropyLoss(input.data.numpy(),target.data.numpy()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer\n",
    "\n",
    "將多個圖形利用自訂的類別建立成一個物件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "# ### Optimizer\n",
    "class DogsAndCatsDataset(Dataset):\n",
    "    def __init__(self,root_dir,size=(224,224)):\n",
    "        self.files = glob(root_dir)\n",
    "        self.size = size\n",
    "        self.arr = np.array([[1,0],[0,1]],float)\n",
    "    def __len__(self):\n",
    "        return len(self.files)\n",
    "    def __getitem__(self,idx):\n",
    "        input = Variable(torch.from_numpy(np.asarray(Image.open(self.files[idx]).resize((1,224*224)), float)))\n",
    "        if(idx<1000):\n",
    "            target = Variable(torch.from_numpy(self.arr[0]))\n",
    "        else:\n",
    "            target = Variable(torch.from_numpy(self.arr[1])) \n",
    "        return input,target\n",
    "\n",
    "dataset=DogsAndCatsDataset(\"D:/program/vscode_workspace/private/data/dogs-vs-cats/classifier/*.jpg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training......\n",
      "Completion ratio : 2.4%\n",
      "Completion ratio : 4.8%\n",
      "Completion ratio : 7.15%\n",
      "Completion ratio : 9.5%\n",
      "Completion ratio : 11.85%\n",
      "Completion ratio : 14.15%\n",
      "Completion ratio : 16.35%\n",
      "Completion ratio : 18.65%\n",
      "Completion ratio : 21.0%\n",
      "Completion ratio : 23.35%\n",
      "Completion ratio : 25.7%\n",
      "Completion ratio : 28.05%\n",
      "Completion ratio : 30.35%\n",
      "Completion ratio : 32.65%\n",
      "Completion ratio : 34.9%\n",
      "Completion ratio : 37.1%\n",
      "Completion ratio : 39.4%\n",
      "Completion ratio : 41.7%\n",
      "Completion ratio : 44.0%\n",
      "Completion ratio : 46.3%\n",
      "Completion ratio : 48.6%\n",
      "Completion ratio : 50.9%\n",
      "Completion ratio : 53.2%\n",
      "Completion ratio : 55.5%\n",
      "Completion ratio : 57.75%\n",
      "Completion ratio : 60.0%\n",
      "Completion ratio : 62.25%\n",
      "Completion ratio : 64.55%\n",
      "Completion ratio : 66.85%\n",
      "Completion ratio : 69.15%\n",
      "Completion ratio : 71.45%\n",
      "Completion ratio : 73.75%\n",
      "Completion ratio : 76.0%\n",
      "Completion ratio : 78.25%\n",
      "Completion ratio : 80.5%\n",
      "Completion ratio : 82.75%\n",
      "Completion ratio : 85.0%\n",
      "Completion ratio : 87.25%\n",
      "Completion ratio : 89.5%\n",
      "Completion ratio : 91.7%\n",
      "Completion ratio : 93.8%\n",
      "Completion ratio : 95.9%\n",
      "Completion ratio : 98.0%\n",
      "MyFirstNetwork(\n",
      "  (layer1): Linear(in_features=50176, out_features=3136, bias=True)\n",
      "  (layer2): Linear(in_features=3136, out_features=2, bias=True)\n",
      ")\n",
      "--------------------------------------\n",
      "layer1 : \n",
      "weight :\n",
      " [[ 0.00190854  0.00210715  0.00040599 ...  0.00106294  0.00062711\n",
      "  -0.00268962]\n",
      " [-0.00314616  0.00280258 -0.00161625 ...  0.0023428  -0.00283227\n",
      "  -0.00019043]\n",
      " [-0.00408834  0.00411934  0.00312982 ... -0.00039291  0.00233806\n",
      "  -0.00081129]\n",
      " ...\n",
      " [-0.00209975 -0.00333113 -0.00226161 ... -0.00437225 -0.00219975\n",
      "   0.00059131]\n",
      " [-0.0010025   0.00268713 -0.00054957 ... -0.00023102  0.00360378\n",
      "  -0.00139874]\n",
      " [ 0.00089735  0.00242361  0.00326251 ...  0.00275627 -0.00343456\n",
      "   0.00313632]] \n",
      "bias :\n",
      " [-0.00201697 -0.00202073  0.00111107 ... -0.00055719  0.00027222\n",
      " -0.0018786 ]\n",
      "\n",
      "layer2 : \n",
      "weight :\n",
      " [[-0.01598472  0.0046289   0.00259414 ... -0.0025138  -0.01723835\n",
      "   0.00130245]\n",
      " [ 0.01238746  0.01350108 -0.0141816  ...  0.01816553 -0.01270212\n",
      "   0.00279518]] \n",
      "bias :\n",
      " [ 0.00450344 -0.00509635]\n",
      "time : 22.209545140099998 min\n",
      "\n",
      "test.....\n",
      "tensor([[3.2666e-04, 9.9967e-01]], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[6.3962e-04, 9.9936e-01]], grad_fn=<SoftmaxBackward>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "from time import perf_counter\n",
    "loss_fn = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.0001,momentum=0.9)\n",
    "print(\"Training......\")\n",
    "\n",
    "index = 0\n",
    "t1 = perf_counter()\n",
    "t  = t1\n",
    "for input, target in dataset:\n",
    "    data=input[:,:,0].view(1,-1).float()+input[:,:,1].view(1,-1).float()+input[:,:,2].view(1,-1).float()\n",
    "    output = model(data/(3*(255.)**2)**0.5)\n",
    "    optimizer.zero_grad()\n",
    "    loss = loss_fn(output, target.float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    index+=1\n",
    "    if(perf_counter()-t > 30):\n",
    "        t = perf_counter()\n",
    "        print(\"Completion ratio :\",str(index*100.0/2000)+\"%\")\n",
    "t2  = perf_counter()\n",
    "\n",
    "print(model)\n",
    "print(\"--------------------------------------\")\n",
    "print(\"layer1 :\",\"\\nweight :\\n\",model.layer()[0][0].numpy(),\"\\nbias :\\n\",model.layer()[0][1].numpy())\n",
    "print(\"\")\n",
    "print(\"layer2 :\",\"\\nweight :\\n\",model.layer()[1][0].numpy(),\"\\nbias :\\n\",model.layer()[1][1].numpy())\n",
    "print(\"time :\",str((t2-t1)/60.0)+\" min\")\n",
    "\n",
    "print(\"\\ntest.....\")\n",
    "test = DogsAndCatsDataset(\"D:/program/vscode_workspace/private/data/dogs-vs-cats/sample_test/*.jpg\")\n",
    "data1=test[0][0][:,:,0].view(1,-1).float()+test[0][0][:,:,1].view(1,-1).float()+test[0][0][:,:,2].view(1,-1).float()\n",
    "data2=test[1][0][:,:,0].view(1,-1).float()+test[1][0][:,:,1].view(1,-1).float()+test[1][0][:,:,2].view(1,-1).float()\n",
    "output1 = model(data1/(3*(255.)**2)**0.5)\n",
    "output2 = model(data2/(3*(255.)**2)**0.5)\n",
    "print(output1)\n",
    "print(output2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
