{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Cheng\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gauss_integral'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-e6a8fae32f22>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mAdam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mRMSprop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSGD\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNadam\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mgauss_integral\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mG_int\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gauss_integral'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os, re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import keras\n",
    "#from keras import backend as K\n",
    "from keras.utils import np_utils\n",
    "from keras.models import Sequential,Model\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten, Input, Reshape\n",
    "from keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.optimizers import Adam, RMSprop, SGD, Nadam\n",
    "import matplotlib.pyplot as plt\n",
    "import gauss_integral as G_int\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "import tensorflow as tf\n",
    "tf.test.is_gpu_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "L = 20\n",
    "Low_Lambda = 0.5\n",
    "High_Lambda = 1/0.2\n",
    "create = True\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # parallelised continuous\n",
    "# from joblib import Parallel, delayed\n",
    "# import multiprocessing\n",
    "# import time\n",
    "# t0=time.time()\n",
    "\n",
    "# num_cores = multiprocessing.cpu_count()\n",
    "# print(num_cores)\n",
    "# def C_matrix_fast(Lambda, L):\n",
    "#         ij = range(int(0-L), int(0+L))\n",
    "#         INT = []\n",
    "#         for i in ij:\n",
    "#             def F(k):\n",
    "#                 return (1.0/np.pi)*( -1*np.sin(k)*np.sin(k*(i)) + (np.cos(k)-Lambda)*np.cos(k*(i))/((np.sin(k)**2+(np.cos(k)-Lambda)**2)**0.5))\n",
    "#             INT.append(G_int.gaussxwint(F, 0, np.pi, 100))\n",
    "\n",
    "#         A = np.zeros([L, L, 1])\n",
    "#         for i in range(L):\n",
    "#             for j in range(L):\n",
    "#                 A[i, j, 0] = INT[i-j-L]\n",
    "#         return A\n",
    "# # count = 0\n",
    "# #1.0/Low_Lambda\n",
    "# # Lambda_range = 0.005\n",
    "# # number_of_training_data = 501 \n",
    "# # AA = [0]*number_of_training_data\n",
    "# # for i in np.linspace(Low_Lambda, Low_Lambda+Lambda_range, number_of_training_data):\n",
    "# points_of_measurement = np.linspace( 0, 10,5000)\n",
    "# def gen_low(i):\n",
    "# #     count += 1\n",
    "#     res=C_matrix_fast(i, L)\n",
    "# #     if count %50 == 1:\n",
    "# #         print ('Low', count)\n",
    "#     return res\n",
    "# lin_input=points_of_measurement\n",
    "# C_matrix= Parallel(n_jobs=num_cores)(delayed(gen_low)(i) for i in lin_input)\n",
    "# # np.save('./training_data/L='+str(L)+'/CBA_L='+str(L)+'Lambda='+str(Low_Lambda)+'_LambdaRange='+str(Lambda_range)+'number_of_training_data='+str(number_of_training_data)+'_mod.npy', AA)\n",
    "# C_matrix=np.array(C_matrix)\n",
    "# print(C_matrix.shape)\n",
    "# # np.save('./training_data/L='+str(L)+'/CBA_L='+str(L)+'Lambda='+str(High_Lambda)+'_LambdaRange='+str(Lambda_range)+'number_of_training_data='+str(number_of_training_data)+'_mod.npy', AA)\n",
    "# # print (\"training data has been produced\")\n",
    "# # print (\"L=\"+str(L)+\" Low=\"+str(Low_Lambda))\n",
    "# np.save('./C_linspace_L=30_0_10_5000.npy',C_matrix)\n",
    "# t1=time.time()\n",
    "# print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_matrix = np.load('./C_linspace_0_10_5000.npy')\n",
    "points_of_measurement = np.linspace( 0, 10,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # parallelised low and high\n",
    "# from joblib import Parallel, delayed\n",
    "# import multiprocessing\n",
    "# import time\n",
    "# t0=time.time()\n",
    "\n",
    "# num_cores = multiprocessing.cpu_count()\n",
    "# print(num_cores)\n",
    "# def C_matrix_fast(Lambda, L):\n",
    "#         ij = range(int(0-L), int(0+L))\n",
    "#         INT = []\n",
    "#         for i in ij:\n",
    "#             def F(k):\n",
    "#                 return (1.0/np.pi)*( -1*np.sin(k)*np.sin(k*(i)) + (np.cos(k)-Lambda)*np.cos(k*(i))/((np.sin(k)**2+(np.cos(k)-Lambda)**2)**0.5))\n",
    "#             INT.append(G_int.gaussxwint(F, 0, np.pi, 100))\n",
    "\n",
    "#         A = np.zeros([L, L, 1])\n",
    "#         for i in range(L):\n",
    "#             for j in range(L):\n",
    "#                 A[i, j, 0] = INT[i-j-L]\n",
    "#         return A\n",
    "# # count = 0\n",
    "# #1.0/Low_Lambda\n",
    "# # Lambda_range = 0.005\n",
    "# # number_of_training_data = 501 \n",
    "# # AA = [0]*number_of_training_data\n",
    "# # for i in np.linspace(Low_Lambda, Low_Lambda+Lambda_range, number_of_training_data):\n",
    "# points_of_measurement_high = np.linspace( 2, 2.005,10)\n",
    "# points_of_measurement_low = np.linspace( 0.500, 0.505,10)\n",
    "# def gen_low(i):\n",
    "# #     count += 1\n",
    "#     res=C_matrix_fast(i, L)\n",
    "# #     if count %50 == 1:\n",
    "# #         print ('Low', count)\n",
    "#     return res\n",
    "# lin_input=points_of_measurement_low\n",
    "# C_matrix_low= Parallel(n_jobs=num_cores)(delayed(gen_low)(i) for i in lin_input)\n",
    "# # np.save('./training_data/L='+str(L)+'/CBA_L='+str(L)+'Lambda='+str(Low_Lambda)+'_LambdaRange='+str(Lambda_range)+'number_of_training_data='+str(number_of_training_data)+'_mod.npy', AA)\n",
    "\n",
    "# # count = 0\n",
    "# # AA = [0]*number_of_training_data\n",
    "# lin_input=points_of_measurement_high\n",
    "# C_matrix_high= Parallel(n_jobs=num_cores)(delayed(gen_low)(i) for i in lin_input)\n",
    "\n",
    "# points_of_measurement = np.append(points_of_measurement_low,points_of_measurement_high)\n",
    "# C_matrix_high = np.array(C_matrix_high)\n",
    "# C_matrix_low = np.array(C_matrix_low)\n",
    "# C_matrix = np.vstack((C_matrix_low, C_matrix_high))\n",
    "# # C_matrix = np.reshape(C_matrix, (len(points_of_measurement), L, L, 1))\n",
    "# print(C_matrix.shape)\n",
    "# # np.save('./training_data/L='+str(L)+'/CBA_L='+str(L)+'Lambda='+str(High_Lambda)+'_LambdaRange='+str(Lambda_range)+'number_of_training_data='+str(number_of_training_data)+'_mod.npy', AA)\n",
    "# # print (\"training data has been produced\")\n",
    "# # print (\"L=\"+str(L)+\" Low=\"+str(Low_Lambda))\n",
    "# np.save('./C_low_high_0.5_10.npy',C_matrix)\n",
    "# t1=time.time()\n",
    "# print(t1-t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C_matrix = np.vstack((C_matrix_high, C_matrix_low))\n",
    "# # C_matrix = np.reshape(C_matrix, (len(points_of_measurement), L, L, 1))\n",
    "# points_of_measurement = np.append(points_of_measurement_high,points_of_measurement_low)\n",
    "# print(C_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if create :\n",
    "#     C_matrix_low = []\n",
    "#     C_matrix_high = []\n",
    "#     def C_matrix_fast(Lambda, L):\n",
    "#             ij = range(int(0-L), int(0+L))\n",
    "#             INT = []\n",
    "#             for i in ij:\n",
    "#                 def F(k):\n",
    "#                     return (1.0/np.pi)*( -1*np.sin(k)*np.sin(k*(i)) \n",
    "#                                         + (np.cos(k)-Lambda)*np.cos(k*(i))/((np.sin(k)**2\n",
    "#                                                                              +(np.cos(k)-Lambda)**2)**0.5))\n",
    "#                 INT.append(G_int.gaussxwint(F, 0, np.pi, 100))\n",
    "\n",
    "#             A = np.zeros([L, L, 1])\n",
    "#             for i in range(L):\n",
    "#                 for j in range(L):\n",
    "#                     A[i, j, 0] = INT[i-j-L]\n",
    "#             return A\n",
    "\n",
    "\n",
    "#     points_of_measurement_high = np.linspace( 0, 1,500)\n",
    "#     points_of_measurement_low = np.linspace( 1, 10,500)\n",
    "    \n",
    "#     for lam in points_of_measurement_high :\n",
    "#         C_matrix_high.append(C_matrix_fast(lam, L))\n",
    "#     for lam in points_of_measurement_low :\n",
    "#         C_matrix_low.append(C_matrix_fast(lam, L))\n",
    "        \n",
    "#     points_of_measurement = np.append(points_of_measurement_low,points_of_measurement_high)\n",
    "#     C_matrix_high = np.array(C_matrix_high)\n",
    "#     C_matrix_low = np.array(C_matrix_low)\n",
    "#     C_matrix = np.append(C_matrix_low, C_matrix_high)\n",
    "#     C_matrix = np.reshape(C_matrix, (len(points_of_measurement), L, L, 1))\n",
    "#     print(C_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "x = shuffle(C_matrix,random_state=20)\n",
    "\n",
    "print(np.min(x))\n",
    "print(np.max(x))\n",
    "x = x - np.min(x)\n",
    "\n",
    "print(np.min(x))\n",
    "print(np.max(x))\n",
    "\n",
    "x = x/np.max(x)\n",
    "# x = x/np.max(np.abs(x))\n",
    "\n",
    "\n",
    "print(np.min(x))\n",
    "print(np.max(x))\n",
    "\n",
    "print (x.shape)\n",
    "\n",
    "\n",
    "A = x[0]\n",
    "A = np.reshape(A, (L, L))\n",
    "plt.imshow(A)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X,valid_X,train_ground,valid_ground = train_test_split(x,\n",
    "                                                             x, \n",
    "                                                             test_size=0.2, \n",
    "                                                             random_state=13)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_of_measurement = np.linspace( 0, 10,5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_input = Input(shape=(L, L, 1))\n",
    "\n",
    "encode = Conv2D(filters=8, \n",
    "                 kernel_size=(3,3), \n",
    "                 input_shape=(L,L,1), \n",
    "                 activation='relu', \n",
    "                 padding='same')(encoded_input)\n",
    "# encode = Conv2D(filters=32, \n",
    "#                  kernel_size=(3,3), \n",
    "#                  activation='relu', \n",
    "#                  padding='same')(encode)\n",
    "# encode = Conv2D(filters=32, \n",
    "#                  kernel_size=(3,3), \n",
    "#                  activation='relu', \n",
    "#                  padding='same')(encode)\n",
    "# encode = Conv2D(filters=32, \n",
    "#                  kernel_size=(3,3), \n",
    "#                  activation='relu', \n",
    "#                  padding='same')(encode)\n",
    "encode = Flatten()(encode)\n",
    "enocode= Dropout(0.5)(encode)\n",
    "encode = Dense(units=20, activation='relu')(encode)\n",
    "# encode = Dense(units=200, activation='relu')(encode)\n",
    "encode = Dense(units=2, activation='tanh')(encode)\n",
    "\n",
    "\n",
    "decode= Dropout(0.5)(encode)\n",
    "decode = Dense(units=20, activation='relu')(decode)\n",
    "\n",
    "# decode = Dense(units=200, activation='relu')(decode)\n",
    "decode = Dense(units=L*L*8, activation='relu')(decode)\n",
    "decode = Reshape((L, L, 8))(decode)\n",
    "# decode = Conv2D(filters=32, \n",
    "#                  kernel_size=(3,3), \n",
    "#                  activation='relu', \n",
    "#                  padding='same')(decode)\n",
    "# decode = Conv2D(filters=32, \n",
    "#                  kernel_size=(3,3), \n",
    "#                  activation='relu', \n",
    "#                  padding='same')(decode)\n",
    "# decode = Conv2D(filters=16, \n",
    "#                  kernel_size=(3,3), \n",
    "#                  activation='relu', \n",
    "#                  padding='same')(decode)\n",
    "decode = Conv2D(filters=1, \n",
    "                 kernel_size=(3,3), \n",
    "                 input_shape=(L,L,1), \n",
    "                 activation='relu', \n",
    "                 padding='same')(decode)\n",
    "\n",
    "autoencoder = Model(encoded_input, decode)\n",
    "encoder = Model(encoded_input, encode)\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 200\n",
    "autoencoder.compile(optimizer= Adam(), loss='mean_squared_error')\n",
    "autoencoder_train = autoencoder.fit(train_X , train_ground , epochs=epochs, validation_data=(valid_X, valid_ground) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = autoencoder_train.history['loss']\n",
    "val_loss = autoencoder_train.history['val_loss']\n",
    "epochs = range(epochs)\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')new_model_shan\n",
    "plt.title('Training and validation loss')\n",
    "\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_json1 = autoencoder.to_json()\n",
    "# model_json2 = encoder.to_json()\n",
    "# with open(\"autoencoder.json\", \"w\") as json_file:\n",
    "#     json_file.write(model_json1)\n",
    "# with open(\"encoder.json\", \"w\") as json_file:\n",
    "#     json_file.write(model_json2)\n",
    "\n",
    "# autoencoder.save_weights(\"autoencoder_weights.h5\")\n",
    "\n",
    "# encoder.save_weights(\"encoder_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save model shan\n",
    "# autoencoder.save('shan_autoencoder.h5')\n",
    "# encoder.save('shan_encoder.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model shan\n",
    "autoencoder=keras.models.load_model('shan_autoencoder.h5')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model shan\n",
    "encoder=keras.models.load_model('shan_encoder.h5')\n",
    "encoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# autoencoder = keras.models.model_from_json(\"autoencoder.json\")\n",
    "# encoder = keras.models.model_from_json(\"encoder.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# encoded_imgs_low = encoder.predict(C_matrix_low)\n",
    "# encoded_imgs_high = encoder.predict(C_matrix_high)\n",
    "\n",
    "C_matrix_augmented = C_matrix - np.min(C_matrix)\n",
    "C_matrix_augmented = C_matrix_augmented/np.max(C_matrix_augmented)\n",
    "\n",
    "encoded_imgs = encoder.predict(C_matrix_augmented)\n",
    "encoded_imgs_copy = np.copy(encoded_imgs)\n",
    "\n",
    "\n",
    "# new_imgs_high = autoencoder.predict(C_matrix_high)\n",
    "# new_imgs_low = autoencoder.predict(C_matrix_low)\n",
    "new_imgs = autoencoder.predict(C_matrix_augmented)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = train_ground[0]\n",
    "A = np.reshape(A, (L, L))\n",
    "plt.imshow(A)\n",
    "plt.show()\n",
    "\n",
    "A = new_imgs[0]\n",
    "A = np.reshape(A, (L, L))\n",
    "plt.imshow(A)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z_val[500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# x_val_low = encoded_imgs_low[:,0]\n",
    "# y_val_low = encoded_imgs_low[:,1]\n",
    "# x_val_high = encoded_imgs_high[:,0]\n",
    "# y_val_high = encoded_imgs_high[:,1]\n",
    "x_val = encoded_imgs[:,0]\n",
    "y_val=  encoded_imgs[:,1]\n",
    "z_val = points_of_measurement\n",
    "\n",
    "\n",
    "# plt.scatter(x_val_low,y_val_low,color='red')\n",
    "# plt.show()\n",
    "# plt.scatter(x_val_high,y_val_high,color='black')\n",
    "# plt.show()\n",
    "\n",
    "plt.scatter(x_val,y_val, c = z_val,s=5)\n",
    "plt.plot([x_val[500]],[y_val[500]],'ro',markersize=2)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.scatter(z_val,x_val,s=0.5)\n",
    "plt.plot([z_val[500]],[x_val[500]],'ro',markersize=5)\n",
    "plt.xlabel(\"Lambda\")\n",
    "plt.ylabel(\"Output of Central Node\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "plt.scatter(z_val,y_val,s=0.5)\n",
    "# plt.plot([z_val[500]],[y_val[500]],'ro',markersize=12)\n",
    "plt.show()\n",
    "\n",
    "# grad=np.gradient(x_val)\n",
    "# plt.xlabel(\"Lambda\")\n",
    "# plt.ylabel(\"Derivative\")\n",
    "# plt.scatter(z_val,grad,s=0.5)\n",
    "# plt.show()\n",
    "\n",
    "# grad=np.gradient(grad)\n",
    "# plt.xlabel(\"Lambda\")\n",
    "# plt.ylabel(\"Derivative\")\n",
    "# plt.scatter(z_val,grad,s=0.5)\n",
    "# # plt.plot([z_val[500]],[y_val[500]],'ro',markersize=12)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import DBSCAN\n",
    "\n",
    "clustering = DBSCAN(eps=0.01).fit(encoded_imgs)\n",
    "plt.xlabel(\"Output of Node 1\")\n",
    "plt.ylabel(\"Output of Node 2\")\n",
    "plt.scatter(x_val,y_val, c = clustering.labels_,s=5)\n",
    "print(clustering.labels_)\n",
    "# plt.plot([x_val[500]],[y_val[500]],'ro',markersize=2)\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(clustering.labels_)\n",
    "window = 10\n",
    "\n",
    "# print(indices)\n",
    "# print(np.where(indices[0]<2))\n",
    "prob_val = []\n",
    "cluster = 1\n",
    "size = len(clustering.labels_)\n",
    "for i in range(size):\n",
    "    if i < window :\n",
    "        values = clustering.labels_[:i+10]\n",
    "    else :\n",
    "        values = clustering.labels_[i-10:i+10]\n",
    "    prob_val.append( len(np.where(values == cluster)[0])/(2*window) )\n",
    "\n",
    "plt.scatter(z_val,prob_val,s=1)\n",
    "plt.xlabel(\"Lambda\")\n",
    "plt.ylabel(\"Probability of data in cluster 1\")\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded_imgs_copy.sort(axis=0)\n",
    "# check_this.sort(axis=0)\n",
    "# print(encoded_imgs.shape)\n",
    "# plt.plot(encoded_imgs)\n",
    "# plt.ylabel('Output of Lambda')\n",
    "# plt.xlabel('Matrix id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# from mpl_toolkits.mplot3d import Axes3D \n",
    "\n",
    "\n",
    "# x_val = encoded_imgs_copy[:,0]\n",
    "# y_val=  encoded_imgs_copy[:,1]\n",
    "# z_val = points_of_measurement\n",
    "\n",
    "# fig = plt.figure()\n",
    "# ax = fig.add_subplot(111, projection='3d')\n",
    "# ax.scatter(x_val, y_val, z_val )\n",
    "\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# plt.scatter(x_val,y_val)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.scatter(z_val,x_val)\n",
    "# plt.show()\n",
    "\n",
    "\n",
    "# plt.scatter(z_val,y_val)\n",
    "# plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# points = []\n",
    "# for i in range(len(points_of_measurement)) :\n",
    "#     points.append((x_val[i],y_val[i],z_val[i]))\n",
    "    \n",
    "# for i in points :\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
