{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of the gradient class activation map: VGG16 as an example\n",
    "ref. https://github.com/jacobgil/keras-grad-cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "import keras\n",
    "import keras.backend as K\n",
    "#from keras.applications.vgg16 import VGG16, preprocess_input, decode_predictions\n",
    "from keras.applications.vgg16 import VGG16, decode_predictions\n",
    "from keras.preprocessing import image\n",
    "from keras.layers.core import Lambda\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Activation, Convolution2D, MaxPooling2D, Flatten, BatchNormalization, Input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "def load_image(path):\n",
    "    img_path = path\n",
    "    img = image.load_img(img_path, target_size=(224, 224))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    # Normalize images with values ranging from 0 to 1 (or from -1 to +1 or mean subtraction), \n",
    "    # depending on the model called \n",
    "    x = preprocess_input(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "test_path = './test/test.jpg'\n",
    "preprocessed_input = load_image(test_path)\n",
    "print(preprocessed_input.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(224, 224, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test only\n",
    "preprocessed_input = preprocessed_input[0,:]\n",
    "preprocessed_input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[77.061   , 47.060997, 77.061   , 62.060997, 73.061   , 53.060997,\n",
       "        70.061   , 71.061   , 37.060997, 73.061   ],\n",
       "       [77.061   , 47.060997, 79.061   , 75.061   , 76.061   , 70.061   ,\n",
       "        70.061   , 67.061   , 39.060997, 62.060997],\n",
       "       [74.061   , 49.060997, 79.061   , 77.061   , 78.061   , 77.061   ,\n",
       "        70.061   , 66.061   , 54.060997, 48.060997],\n",
       "       [77.061   , 57.060997, 80.061   , 78.061   , 78.061   , 75.061   ,\n",
       "        72.061   , 64.061   , 53.060997, 47.060997],\n",
       "       [51.060997, 53.060997, 79.061   , 79.061   , 77.061   , 77.061   ,\n",
       "        73.061   , 63.060997, 57.060997, 43.060997],\n",
       "       [51.060997, 55.060997, 79.061   , 78.061   , 78.061   , 77.061   ,\n",
       "        74.061   , 61.060997, 63.060997, 60.060997],\n",
       "       [55.060997, 56.060997, 79.061   , 79.061   , 78.061   , 76.061   ,\n",
       "        74.061   , 66.061   , 69.061   , 68.061   ],\n",
       "       [65.061   , 60.060997, 70.061   , 77.061   , 76.061   , 77.061   ,\n",
       "        76.061   , 75.061   , 73.061   , 68.061   ],\n",
       "       [62.060997, 72.061   , 53.060997, 80.061   , 76.061   , 75.061   ,\n",
       "        74.061   , 74.061   , 75.061   , 67.061   ],\n",
       "       [58.060997, 66.061   , 49.060997, 79.061   , 79.061   , 75.061   ,\n",
       "        72.061   , 72.061   , 72.061   , 67.061   ]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test only\n",
    "preprocessed_input[20:30, 20:30, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "channelsize = (224, 224)\n",
    "conv1,conv2,linear = (3, 3, 5, 1, 'same'), (3, 3, 5, 1, 'same'), (\"\", 512, 4)\n",
    "\n",
    "def resnet(input_shape):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = Convolution2D(batch_input_shape=(None, channelsize[0], channelsize[1], conv1[0]), \n",
    "                      filters=conv1[1], \n",
    "                      kernel_size=conv1[2], \n",
    "                      strides=conv1[3],\n",
    "                      padding=conv1[4])(inputs)\n",
    "    x = BatchNormalization()(x)    \n",
    "    x = Activation('relu')(x)\n",
    "    x = Convolution2D(filters=conv2[1], \n",
    "                      kernel_size=conv2[2], \n",
    "                      strides=conv2[3],\n",
    "                      padding=conv2[4])(x)\n",
    "    x = BatchNormalization()(x)    \n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = keras.layers.add([x,inputs])\n",
    "    \n",
    "    x = Flatten()(x)\n",
    "    x = Dense(linear[1])(x)\n",
    "    x = Dense(linear[2])(x)\n",
    "    outputs = Activation('softmax')(x)\n",
    "    \n",
    "    return Model(inputs=inputs,outputs=outputs)\n",
    "\n",
    "model = resnet((channelsize[0], channelsize[1], conv1[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(224, 224, 3)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "`decode_predictions` expects a batch of predictions (i.e. a 2D array of shape (samples, 1000)). Found array with shape: (1, 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-f3142a001907>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocessed_input\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpreprocessed_input\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m224\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtop_1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecode_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m# top_1 structure looks like [[(class, class description, score),...,(a5,b5,c5)]]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\applications\\__init__.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'models'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'utils'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mbase_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras\\applications\\vgg16.py\u001b[0m in \u001b[0;36mdecode_predictions\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0mkeras_modules_injection\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mdecode_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mvgg16\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecode_predictions\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\keras_applications\\imagenet_utils.py\u001b[0m in \u001b[0;36mdecode_predictions\u001b[1;34m(preds, top, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m                          \u001b[1;34m'a batch of predictions '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m                          \u001b[1;34m'(i.e. a 2D array of shape (samples, 1000)). '\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m                          'Found array with shape: ' + str(preds.shape))\n\u001b[0m\u001b[0;32m    223\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mCLASS_INDEX\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m         fpath = keras_utils.get_file(\n",
      "\u001b[1;31mValueError\u001b[0m: `decode_predictions` expects a batch of predictions (i.e. a 2D array of shape (samples, 1000)). Found array with shape: (1, 4)"
     ]
    }
   ],
   "source": [
    "#model = VGG16(weights='imagenet')\n",
    "print(np.shape(preprocessed_input))\n",
    "predictions = model.predict(preprocessed_input.reshape(-1, 224, 224, 3))\n",
    "top_1 = decode_predictions(predictions)[0][0]\n",
    "# top_1 structure looks like [[(class, class description, score),...,(a5,b5,c5)]]\n",
    "\n",
    "predicted_class = np.argmax(predictions)\n",
    "print('Predicted class:', predicted_class)\n",
    "print('%s (%s) with probability %.2f' % (top_1[1], top_1[0], top_1[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grad-CAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_category_loss(x, category_index, nb_classes):\n",
    "    return tf.multiply(x, K.one_hot([category_index], nb_classes))\n",
    "\n",
    "def target_category_loss_output_shape(input_shape):\n",
    "    return input_shape\n",
    "\n",
    "def normalize(x):\n",
    "    # utility function to normalize a tensor by its L2 norm\n",
    "    #return x / (K.sqrt(K.mean(K.square(x))) + 1e-5)\n",
    "    return x / (K.sqrt(K.sum(K.square(x))) + 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test only\n",
    "with tf.Session() as sess:\n",
    "    x = tf.constant([[1., 2.], [1., 2.]])\n",
    "    ans = normalize(x)\n",
    "    print(sess.run(ans))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_cam(input_model, image, category_index, layer_name):\n",
    "    # cam, heatmap = grad_cam(model, preprocessed_input, predicted_class, \"block5_conv3\")\n",
    "    nb_classes = 1000\n",
    "    target_layer = lambda x: target_category_loss(x, category_index, nb_classes)\n",
    "    # Add a self-defined layer by using Lambda\n",
    "    x = Lambda(target_layer, output_shape = target_category_loss_output_shape)(input_model.output)\n",
    "    model = Model(inputs=input_model.input, outputs=x)\n",
    "    model.summary()\n",
    "\n",
    "    loss = K.sum(model.output)\n",
    "    conv_output =  [l for l in model.layers if l.name is layer_name][0].output\n",
    "    \n",
    "    # Compute dy/dA \n",
    "    gradient_function = K.function([model.input], [conv_output, normalize(K.gradients(loss, [conv_output])[0])])\n",
    "    \n",
    "    output, grads_val = gradient_function([image]) # Output is in numpy format\n",
    "    output, grads_val = output[0, :], grads_val[0, :, :, :]\n",
    "    \n",
    "    weights = np.mean(grads_val, axis = (0, 1))\n",
    "    cam = np.ones(output.shape[0 : 2], dtype = np.float32)\n",
    "    # ith feature map, weight w\n",
    "    for i, w in enumerate(weights):\n",
    "        cam += w * output[:, :, i] # \\sum w*A\n",
    "\n",
    "    cam = cv2.resize(cam, (224, 224))\n",
    "    cam = np.maximum(cam, 0)\n",
    "    heatmap = cam / np.max(cam)\n",
    "\n",
    "    #Return to BGR [0-255] from the preprocessed image\n",
    "    image = image[0, :]\n",
    "    image -= np.min(image)\n",
    "    image = np.minimum(image, 255)\n",
    "\n",
    "    cam = cv2.applyColorMap(np.uint8(255*heatmap), cv2.COLORMAP_JET)\n",
    "    cam = np.float32(cam) + np.float32(image)\n",
    "    cam = 255 * cam / np.max(cam)\n",
    "    return np.uint8(cam), heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_gradient():\n",
    "    if \"GuidedBackProp\" not in ops._gradient_registry._registry:\n",
    "        @ops.RegisterGradient(\"GuidedBackProp\")\n",
    "        def _GuidedBackProp(op, grad):\n",
    "            dtype = op.inputs[0].dtype\n",
    "            return grad * tf.cast(grad > 0., dtype) * tf.cast(op.inputs[0] > 0., dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def modify_backprop(model, name):\n",
    "    g = tf.get_default_graph()\n",
    "    with g.gradient_override_map({'Relu': name}):\n",
    "\n",
    "        # get layers that have an activation\n",
    "        layer_dict = [layer for layer in model.layers[1:] if hasattr(layer, 'activation')]\n",
    "        # replace relu activation\n",
    "        for layer in layer_dict:\n",
    "            if layer.activation == keras.activations.relu:\n",
    "                layer.activation = tf.nn.relu\n",
    "\n",
    "        # re-instanciate a new model\n",
    "        new_model = VGG16(weights='imagenet')\n",
    "    return new_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compile_saliency_function(model, activation_layer='block5_conv3'):\n",
    "    input_img = model.input\n",
    "    layer_dict = dict([(layer.name, layer) for layer in model.layers[1:]])\n",
    "    layer_output = layer_dict[activation_layer].output\n",
    "    max_output = K.max(layer_output, axis=3)\n",
    "    saliency = K.gradients(K.sum(max_output), input_img)[0]        # saliency.shape = input_img.shape\n",
    "    return K.function([input_img, K.learning_phase()], [saliency]) #test: K.learning_phase()=0; train: 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deprocess_image(x):\n",
    "    '''\n",
    "    Same normalization as in:\n",
    "    https://github.com/fchollet/keras/blob/master/examples/conv_filter_visualization.py\n",
    "    '''\n",
    "    if np.ndim(x) > 3:\n",
    "        x = np.squeeze(x)\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    if K.image_dim_ordering() == 'th':\n",
    "        x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creat grad_cam\n",
    "gcam, heatmap = grad_cam(model, preprocessed_input, predicted_class, \"block5_conv3\")\n",
    "cv2.imwrite(\"gradcam.jpg\", gcam)\n",
    "\n",
    "# Creat guided_grad_cam\n",
    "register_gradient()\n",
    "guided_model = modify_backprop(model, 'GuidedBackProp')\n",
    "saliency_fn = compile_saliency_function(guided_model)\n",
    "saliency = saliency_fn([preprocessed_input, 0])      # saliency.shape = (1, input_img.shape)\n",
    "gradcam = saliency[0] * heatmap[..., np.newaxis]     # heatmap.shape expands to (height, width, 1)\n",
    "cv2.imwrite(\"guided_gradcam.jpg\", deprocess_image(gradcam))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test only: broadcasting properties\n",
    "mA = np.array([[[1.,2.],[3.,4.]]]) # (1,2,2)\n",
    "print('mA.shape=', mA.shape)\n",
    "mB = np.array([[1.,2.],[3.,4.]])   # (2,2)\n",
    "print('mB.shape=', mB.shape)\n",
    "mC = mA * mB\n",
    "print('mC.shape=', mC.shape)\n",
    "print('mC =', mC)\n",
    "mA2 = np.array([[[[1.,1.1,1.2],[2.,2.1,2.2]],[[3.,3.1,3.2],[4.,4.1,4.2]]]]) # (1,2,2,3)\n",
    "print('mA2.shape=', mA2.shape)\n",
    "mB2 = mB[..., np.newaxis]\n",
    "print('mB2.shape=', mB2.shape)\n",
    "mC2 = mA2 * mB2\n",
    "print('mC2.shape=', mC2.shape)\n",
    "print('mC2 =', mC2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
